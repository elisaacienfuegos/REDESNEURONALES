{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vYeU3mWbc_G"
      },
      "outputs": [],
      "source": [
        "# --- LibrerÃ­as bÃ¡sicas ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- LibrerÃ­as de Deep Learning ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# --- LibrerÃ­as de Preprocesamiento ---\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# --- LibrerÃ­as de VisualizaciÃ³n ---\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Confirmar que se han importado correctamente\n",
        "print(\"âœ… LibrerÃ­as importadas correctamente.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://drive.google.com/uc?id=1Xt9my-us-GRPWBzhDrbdRgi9fznXlLow\"\n",
        "\n",
        "# Generamos nuestro dataframe\n",
        "dataframe = pd.read_csv(url)\n",
        "display(dataframe)"
      ],
      "metadata": {
        "id": "slPOpp1ndFwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_usa= dataframe[dataframe['Country'] == 'USA']\n",
        "display(customers_usa)"
      ],
      "metadata": {
        "id": "jiwgVGpzGk6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_usa_clean= customers_usa.copy()"
      ],
      "metadata": {
        "id": "eWH8XrxCHF7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "customers_usa_clean.loc[:, 'Gender_Numeric'] = customers_usa_clean['Gender'].map({'Male': 0, 'Female': 1})\n",
        "display(customers_usa_clean.head(10))"
      ],
      "metadata": {
        "id": "psHmqJbmHTqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "customers_usa_clean.loc[:, \"Loyalty_Gold\"] = (customers_usa_clean[\"LoyaltyLevel\"] == \"Gold\").astype(int)\n",
        "customers_usa_clean.loc[:, \"Loyalty_Silver\"] = (customers_usa_clean[\"LoyaltyLevel\"] == \"Silver\").astype(int)\n",
        "customers_usa_clean.loc[:, \"Loyalty_Bronze\"] = (customers_usa_clean[\"LoyaltyLevel\"] == \"Bronze\").astype(int)\n",
        "display(customers_usa_clean.head(10))\n"
      ],
      "metadata": {
        "id": "KEVqnzOuHam2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizamos las columnas del dataset\n",
        "print(customers_usa_clean.columns)\n",
        "\n",
        "# Eliminamos las columas que ya no son relevantes para nuestro dataset\n",
        "customers_usa_clean.drop([\"Gender\", \"LoyaltyLevel\"], axis=1, inplace=True)\n",
        "display(customers_usa_clean.head(10))"
      ],
      "metadata": {
        "id": "DRHOlgeRHdRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminamos la columna 'CustomerID'\n",
        "customers_usa_clean.drop([\"CustomerID\"], axis=1, inplace=True)\n",
        "\n",
        "# Eliminamos la columna 'Country'\n",
        "customers_usa_clean.drop([\"Country\"], axis=1, inplace=True)\n",
        "\n",
        "customers_usa_clean.drop([\"SatisfactionScore\"], axis=1, inplace=True)\n",
        "\n",
        "# Mostramos las primeras filas para confirmar que han sido eliminadas\n",
        "customers_usa_clean.head(10)\n"
      ],
      "metadata": {
        "id": "Sfg58WZHHgjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Seleccionar 5.000 filas de manera aleatoria ---\n",
        "customers_usa_clean = customers_usa_clean.sample(5000, random_state=40).reset_index(drop=True)\n",
        "\n",
        "# --- Definir X (features) e y (target) ---\n",
        "X = customers_usa_clean.drop(columns=['FeedbackScore'])\n",
        "y = customers_usa_clean['FeedbackScore']\n",
        "\n",
        "# --- Codificar etiquetas de y ---\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# --- Dividir en conjuntos de entrenamiento y test ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=40)\n",
        "\n",
        "# --- Escalar los datos ---\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)  # Ajustamos solo con el entrenamiento\n",
        "\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# --- Convertir datos a tensores ---\n",
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# --- Crear dataset y dataloader ---\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# --- Mostrar tamaÃ±os de los datasets ---\n",
        "print(f\"âœ… Datos preparados. TamaÃ±o X_train: {X_train_tensor.shape}, TamaÃ±o y_train: {y_train_tensor.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "UUxai7zndSnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## --- Definir Red Neuronal ---\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(9, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 3)  # 3 clases posibles\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for lr in [0.001, 0.01, 0.1]:\n",
        "    for momentum in [0.5, 0.9]:\n",
        "        model = NeuralNetwork()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "        # Entrenamiento (solo 5 epochs para evaluar rÃ¡pido)\n",
        "        for epoch in range(30):\n",
        "            for inputs, labels in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # EvaluaciÃ³n en test\n",
        "        with torch.no_grad():\n",
        "            outputs = model(X_test_tensor)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
        "\n",
        "        print(f\"lr={lr}, momentum={momentum}, accuracy={accuracy:.4f}\")\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_params = {'lr': lr, 'momentum': momentum}\n",
        "\n",
        "print(f\"\\nðŸš€ Mejor combinaciÃ³n encontrada: {best_params}, con accuracy: {best_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "qJ0Aq7b6dULt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Entrenar la red neuronal ---\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Mostrar pÃ©rdida cada 5 Ã©pocas\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"ðŸ“ˆ Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "print(\"âœ… Entrenamiento finalizado.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "p6aYNdhLdVm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Invertir codificaciÃ³n de etiquetas para mostrar predicciones ---\n",
        "predicted_labels = label_encoder.inverse_transform(predicted.numpy())\n",
        "real_labels = label_encoder.inverse_transform(y_test_tensor.numpy())\n",
        "\n",
        "# --- Crear DataFrame de comparaciÃ³n ---\n",
        "results = pd.DataFrame({'Real': real_labels, 'Predicho': predicted_labels})\n",
        "\n",
        "# --- Mostrar 15 ejemplos ---\n",
        "print(\"Muestra de predicciones reales vs predichas:\")\n",
        "print(results.sample(30, random_state=40))\n"
      ],
      "metadata": {
        "id": "QiUEA743fItQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(confusion_matrix(y_test_tensor, predicted))\n",
        "print(classification_report(y_test_tensor, predicted, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "r-6YPIJwjAbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuevos clientes\n",
        "nuevos_clientes = pd.DataFrame({\n",
        "    'Age': [35, 52],\n",
        "    'Income': [75000, 62000],\n",
        "    'ProductQuality': [8, 6],\n",
        "    'ServiceQuality': [9, 7],\n",
        "    'PurchaseFrequency': [15, 20],\n",
        "    'Gender_Numeric': [1, 0],\n",
        "    'Loyalty_Gold': [0, 1],\n",
        "    'Loyalty_Silver': [1, 0],\n",
        "    'Loyalty_Bronze': [0, 0]\n",
        "})\n",
        "\n",
        "# Reordenar columnas para que coincidan con X_train\n",
        "nuevos_clientes = nuevos_clientes[X_train.columns]\n",
        "\n",
        "# Escalar\n",
        "nuevos_escalados = scaler.transform(nuevos_clientes)\n",
        "\n",
        "# Convertir a tensor\n",
        "nuevos_tensor = torch.tensor(nuevos_escalados, dtype=torch.float32)\n",
        "\n",
        "# PredicciÃ³n\n",
        "with torch.no_grad():\n",
        "    predicciones = model(nuevos_tensor)\n",
        "    _, clases_predichas = torch.max(predicciones, 1)\n",
        "\n",
        "# Decodificar categorÃ­as\n",
        "categorias_predichas = label_encoder.inverse_transform(clases_predichas.numpy())\n",
        "\n",
        "# Mostrar resultados\n",
        "for i, categoria in enumerate(categorias_predichas, 1):\n",
        "    print(f\"Cliente {i} â†’ PredicciÃ³n de satisfacciÃ³n: {categoria}\")\n"
      ],
      "metadata": {
        "id": "MvPJuO9mOKZJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}